\documentclass[11pt,a4paper,english]{article}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[round]{natbib}
\usepackage[margin=1in]{geometry}  % set the margins to 1in on all sides
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}

\newcommand{\PP}{\mathbb{P}}      % for Prob
\newcommand{\EE}{\mathbb{E}}      % for Expectation

\begin{document}
\title{Discrete Optimization Assignment 2}
\author{Quintin Hill, Chi Pham, William Sprent}
\maketitle
\tableofcontents
\clearpage

\section{Theoretical part}
The Randomized Rounding algorithm picks a collection $\mathcal{C}$ of sets to include in
the final solution. We wish to find the probability that at least $\frac{n}{2}$ sets and
the total cost of the sets $c(\mathcal{C})$ is less than $O(OPT)$.

We will equivalently bound the probability that the number of uncovered elements, $|NC|$,
exceeds $\frac{n}{2}$, and that $c(\mathcal{C}) \geq O(OPT_f)$. We will bound these seperately
and combine them by union bound.

\paragraph{Case 1 ( $c(\mathcal{C}) \geq O(OPT_f)$):}
We note that we have,
$$\EE[\mathrm{cost}(\mathcal{C})] = \mathrm{OPT}_f\mathnormal{.}$$
By applying Markov's inequality, we get
\begin{align*}
\PP[\mathrm{cost}(\mathcal{C}) \geq O(\mathrm{OPT}_f)]
  \leq \frac{\mathrm{OPT}_f}{O(\mathrm{OPT}_f)}
  = \frac{1}{c}
\end{align*}
for some constant, $c$. Where denominator in $\frac{\mathrm{OPT}_f}{O(\mathrm{OPT}_f)}$ should be interpreted as
 \textit{any function in $O(\mathrm{OPT}_f)$}, all of which are seperated by $OPT_f$ by a constant factor.

\paragraph{Case 2 ($|NC| \geq \frac{n}{2}$):}
We have that the probability that an element, $a$, is uncovered, $a \in NC$, is the following
$$\PP[a \in NC] \leq \frac{1}{e}$$
\citep[p. 121]{Vaz}.
Then we have that the expected number of uncovered elements is the following,
$$\EE[|NC|] = \sum_a \PP[a \in NC] \leq \frac{n}{e}\mathnormal{.}$$
Then we can derive a bound, by applying Markov's inequality again,
\begin{align*}
  \PP\left[|NC| \geq \frac{n}{2}\right] \leq \frac{\EE[|NC|]}{\frac{n}{2}}
                             \leq \frac{\frac{n}{e}}{\frac{n}{2}} 
                             = \frac{2}{e}\mathnormal{.}
\end{align*}

\paragraph{Combined Bound}
We then combine the bounds by union bound which gives us
$$\PP\left[\mathrm{cost}(\mathcal{C}) \geq O(\mathrm{OPT}_f) \vee  |NC| \geq \frac{n}{2} \right]
\leq \frac{1}{c} + \frac{2}{e}$$
for some constant $c$.

This is not a particularly strong bound as $\frac{2}{e} \approx 0.74$, i.e. the probability of the inverse ($\mathcal{C}$ covers at least half the vertices at a cost of at most $O(OPT)$) will be lower-bounded by some constant value approximately $0.26 - \frac{1}{c}$ for some constant $c$.

\clearpage


\section{Implementation part}

We report the best Solutions in Table \ref{tab:res} and Computational Time in Table \ref{tab:time} against each of the instances for each of the methods. For the two tables, n represents number of times run. As well Simplified Rounding is represented by (SR), Randomized Rounding by (RR), Primal-Dual Method(PDM).

\begin{table}[h!]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}\hline
    Instance& $n$& CPLEX(ILP)&CPLEX(LP)&SR&RR&PDM  \\\hline
    scpa3.dat &$10$&$232$ & $228$ & $490$& $369$ & $448$  \\
    scpc3.dat &$10$&$243$ & $234.58$ & $587$& $442.7$ & $463$ \\
    scpnrf1.dat &$10$&$14$ & $8.8$ & $78$& $29.7$ & $43.0$  \\
    scpnrg5.dat &$10$&-- & $148.23$ & $621$& $382.1$ & $412$  \\\hline
  \end{tabular}
  \caption{Results of methods on their Solution Value}
  \label{tab:res}
\end{table}

We note that the approximated solutions given by our three methods generally have about double the cost of the optimal solution to the ILP.
Moreover, the RR and PDM methods seem to give tighter approximations than the SR method. RR and PDM are comparatively close, but RR outperforms PDM
on two of the datasets.

Since all of the approximation methods are $f$-approximations \citep[pp. 118-131]{Vaz} they all stay well within their ``guarantees''.

\begin{table}[h!]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}\hline
    Instance& $n$& CPLEX(ILP)&SR&RR&PDM \\\hline
    scpa3.dat &$10$&$724.0$ & $238.4$& $239.5$ & $238.5$  \\
    scpc3.dat &$10$ & $3400.3$ & $359.4$& $363.8$ & $368.0$ \\
    scpnrf1.dat	 &$10$ & $28383.5$ & $5506.4$& $5552.0$ & $5629.8$  \\
    scpnrg5.dat &$10$ & -- & $1931.3$& $1926.0$ & $1925.8$  \\\hline
  \end{tabular}
  \caption{Results for Computational Time in ms}
  \label{tab:time}
\end{table}

 Unsurprisingly, the approximation methods run much faster than Cplex takes to find the exact solution. All three of our methods take pretty much the same amount of time.

 Note that the timing is taken from the moment we load the models and data in from the files to the completion of the algorithms. By only taking the time of the file loading and LP relaxation solving, we observed times similar to the approximation algorithm times. This would indicate that the majority of the time is spent on solving the LP relaxation, and the time spent on solving the approximations is trivial.\\

Regarding the theoretical results, we tested them by running just the first iteration of the randomized rounding algorithm and counting the covered vertices. This was done 100 times and averaged for each data set. The results can be seen in Table \ref{tab:rand}.

\begin{table}[h!]
  \centering
  \begin{tabular}{|c|c|c|c|c|}\hline
    Instance& $n$ & Number of elements & Elements covered first iteration & Fraction covered\\\hline
    scpa3.dat &$100$    & $300$ & $270.4$ & 0.90 \\
    scpc3.dat &$100$    & $400$ & $358.21$ & 0.89\\
    scpnrf1.dat	 &$100$ & $500$ & $395.65$ & 0.79 \\
    scpnrg5.dat &$100$  & $1000$ & $856.96$ & 0.86 \\\hline
  \end{tabular}
  \caption{Average covered elements in first iteration, randomized rounding.}
  \label{tab:rand}
\end{table}

As we can see from the table, the average fraction of vertices covered in the first iteration is well over one half, which is consistent with the expectation from the theoretical part.

\clearpage
\bibliographystyle{abbrvnat}
\bibliography{./lit.bib}
% bibtex do-2
\end{document}